{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T08:23:01.025094Z",
     "start_time": "2023-06-22T08:22:57.181048Z"
    },
    "is_executing": true,
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T08:23:01.417150Z",
     "start_time": "2023-06-22T08:23:01.027106Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/price.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2212\\272391245.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data/price.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Set date-time index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprice\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Date\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'%Y/%m/%d'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"Date\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nisha\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nisha\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nisha\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nisha\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nisha\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[0;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nisha\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/price.csv'"
     ]
    }
   ],
   "source": [
    "price = pd.read_csv(\"data/price.csv\")\n",
    "\n",
    "# Set date-time index\n",
    "price = price.set_index(pd.to_datetime(price[\"Date\"], format='%Y/%m/%d'))\n",
    "price.drop(columns = [\"Date\"], inplace = True)\n",
    "\n",
    "# Drop all columns which only contain nan values\n",
    "boolean = []\n",
    "for stock in price.columns:\n",
    "    boolean.append(not price[stock].isnull().all())\n",
    "price = price.iloc[:, boolean]\n",
    "\n",
    "price=(price-price.mean())/price.std()\n",
    "price.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T08:53:57.773765Z",
     "start_time": "2023-06-21T08:53:57.773765Z"
    }
   },
   "outputs": [],
   "source": [
    "describe = price.describe()\n",
    "describe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Line plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T08:53:57.776085Z",
     "start_time": "2023-06-21T08:53:57.776085Z"
    }
   },
   "outputs": [],
   "source": [
    "price_monthly_resampling = price.resample(\"1M\").mean()\n",
    "price_monthly_resampling.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Line plot using normal scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T08:53:57.778565Z",
     "start_time": "2023-06-21T08:53:57.778565Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "sns.lineplot(data=price_monthly_resampling, legend=False, palette=['b']*price_monthly_resampling.shape[1], dashes=False, alpha=0.2);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution of statistics of features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "* Try to create the last bin in the histogram have all the values above that particular bin\n",
    "* I don't think the barplots are neccessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T08:53:57.779865Z",
     "start_time": "2023-06-21T08:53:57.779865Z"
    }
   },
   "outputs": [],
   "source": [
    "# for stat in ('min', 'mean', 'max', 'std', 'count'):\n",
    "#     plt.figure(figsize=(15,8))\n",
    "#     stat_stocks = describe.loc[stat,:].sort_values()\n",
    "#     sns.barplot(x = price.columns, y = stat_stocks)\n",
    "#\n",
    "#     plt.figure(figsize=(15,8))\n",
    "#     sns.histplot(stat_stocks)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T08:53:57.780870Z",
     "start_time": "2023-06-21T08:53:57.780870Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove the variation which exists in all the stocks !!\n",
    "means = price.mean(axis=1).values\n",
    "for r in range(price.shape[0]):\n",
    "    price.iloc[r,:] = price.iloc[r,:] - means[r]\n",
    "price=(price-price.mean())/price.std()\n",
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T08:53:57.782920Z",
     "start_time": "2023-06-21T08:53:57.782920Z"
    }
   },
   "outputs": [],
   "source": [
    "price_monthly_resampling = price.resample(\"1M\").mean()\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.lineplot(data=price_monthly_resampling, legend=False, palette=['b']*price_monthly_resampling.shape[1], dashes=False, alpha=0.2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T08:53:57.783924Z",
     "start_time": "2023-06-21T08:53:57.783924Z"
    }
   },
   "outputs": [],
   "source": [
    "scores_df = price.corr() #.iloc[1:,:price.shape[1]-1]\n",
    "\n",
    "scores = np.nan_to_num(scores_df.to_numpy())\n",
    "scores[np.triu_indices(scores.shape[1])] = np.nan\n",
    "scores_df = pd.DataFrame(scores, index = scores_df.index, columns=scores_df.columns)\n",
    "# scores_df = scores_df.iloc[1:,:scores_df.shape[1]-1]\n",
    "scores_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods for grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T08:53:57.786030Z",
     "start_time": "2023-06-21T08:53:57.786030Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to get index of max value in array without considering a set of indices\n",
    "def get_max_index_except_indices(arr, exceptions):\n",
    "    idx = list(range(len(arr)))   # simple array of index\n",
    "    a1 = np.delete(idx, exceptions)   # remove exceptions from idx (i.e., index)\n",
    "    a2 = np.argmax(np.delete(arr, exceptions))   # get index of the max value after removing exceptions from actual arr array\n",
    "    return a1[a2] # as a1 and a2 are in sync, this will give the original index of the max value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T08:53:57.787031Z",
     "start_time": "2023-06-21T08:53:57.787031Z"
    }
   },
   "outputs": [],
   "source": [
    "def flatten_table(groups):\n",
    "    lst = []\n",
    "    for i in groups:\n",
    "        lst += i\n",
    "    return set(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T08:53:57.790202Z",
     "start_time": "2023-06-21T08:53:57.790202Z"
    }
   },
   "outputs": [],
   "source": [
    "# Checks if a stock has any stocks left to compare to that aren't already grouped\n",
    "def stocks_left_to_compare_with(row_index_of_stock, already_grouped_from_columns, already_grouped_from_index):\n",
    "    flat_groups = flatten_table(groups)\n",
    "    stocks_to_compare = scores_columns[:row_index_of_stock+1]\n",
    "    for s in stocks_to_compare:\n",
    "        if s not in flat_groups:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T08:53:57.792247Z",
     "start_time": "2023-06-21T08:53:57.792247Z"
    }
   },
   "outputs": [],
   "source": [
    "def indices_of_grouped_stocks(row_index_of_stock):\n",
    "    indices = []\n",
    "    flat_groups = flatten_table(groups)\n",
    "    stocks_in_row = scores_columns[:row_index_of_stock+1]\n",
    "\n",
    "    for i, stock in enumerate(stocks_in_row):\n",
    "        if stock in flat_groups:\n",
    "            indices.append(i)\n",
    "\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T08:53:57.794339Z",
     "start_time": "2023-06-21T08:53:57.794339Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find index of max value in matrix excluding certain rows and columns\n",
    "def max_matrix_excluding(rows_exclude, cols_exclude):\n",
    "    rows_exclude, cols_exclude = list(rows_exclude), list(cols_exclude)\n",
    "    over_last_index = len(price.columns.drop(stocks_to_drop))-1\n",
    "\n",
    "    for i in rows_exclude:\n",
    "        if i+1 not in (-1, over_last_index):\n",
    "            cols_exclude.append(i+1)\n",
    "\n",
    "    for i in cols_exclude:\n",
    "        if i-1 not in (-1, over_last_index):\n",
    "            rows_exclude.append(i-1)\n",
    "\n",
    "    idx = list(range(len(scores_index)))\n",
    "    cols_idx = list(range(len(scores_columns)))\n",
    "    idx_a1 = np.delete(idx, rows_exclude)  # remove exceptions from idx (i.e., index)\n",
    "    cols_a1 = np.delete(cols_idx, cols_exclude)   # remove exceptions from idx (i.e., index)\n",
    "\n",
    "    # Remove exceptions from actual matrix and get the index of the max\n",
    "    new_scores = np.delete(scores, cols_exclude, 1) # remove cols\n",
    "    new_scores = np.delete(new_scores, rows_exclude, 0) # remove rows\n",
    "\n",
    "    i, j = np.unravel_index(np.nanargmax(new_scores), new_scores.shape)\n",
    "\n",
    "    return idx_a1[i], cols_a1[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T08:53:57.795336Z",
     "start_time": "2023-06-21T08:53:57.795336Z"
    }
   },
   "outputs": [],
   "source": [
    "def remaining_stocks(scores, rows_exclude, cols_exclude):\n",
    "    rows_exclude, cols_exclude = list(rows_exclude), list(cols_exclude)\n",
    "    over_last_index = len(price.columns.drop(stocks_to_drop))-1\n",
    "\n",
    "    for i in rows_exclude:\n",
    "        if i+1 not in (-1, over_last_index):\n",
    "            cols_exclude.append(i+1)\n",
    "\n",
    "    for i in cols_exclude:\n",
    "        if i-1 not in (-1, over_last_index):\n",
    "            rows_exclude.append(i-1)\n",
    "\n",
    "    # Remove exceptions from actual matrix and get the index of the max\n",
    "    new_scores = np.delete(scores, cols_exclude, 1) # remove cols\n",
    "    new_scores = np.delete(new_scores, rows_exclude, 0) # remove rows\n",
    "\n",
    "    return new_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T08:53:57.797235Z",
     "start_time": "2023-06-21T08:53:57.797235Z"
    }
   },
   "outputs": [],
   "source": [
    "def number_of_groups_with_length_greater_than_2(groups):\n",
    "    length = 0\n",
    "    for group in groups:\n",
    "        if len(group)>2:\n",
    "            length += 1\n",
    "    return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T08:53:57.799274Z",
     "start_time": "2023-06-21T08:53:57.799274Z"
    }
   },
   "outputs": [],
   "source": [
    "# For a particular grouping, find the median score for each group of stocks and find the mean of those medians and\n",
    "# return it\n",
    "\n",
    "def score_grouping(groups):\n",
    "    scores = scores_df.copy()\n",
    "\n",
    "    medians = []\n",
    "    for group in groups:\n",
    "        if len(group) == 1:\n",
    "            continue\n",
    "        group_scores = []\n",
    "        for i, stock_i in enumerate(group):\n",
    "            for stock_j in group[i+1:]:\n",
    "                try:\n",
    "                    s = scores.loc[stock_i,stock_j]\n",
    "                except KeyError:\n",
    "                    s = scores.loc[stock_j,stock_i]\n",
    "                    group_scores.append(s)\n",
    "                    continue\n",
    "                else:\n",
    "                    if np.isnan(s):\n",
    "                        s = scores.loc[stock_j,stock_i]\n",
    "                        group_scores.append(s)\n",
    "                        continue\n",
    "                    group_scores.append(s)\n",
    "                    continue\n",
    "        medians.append(np.median(group_scores))\n",
    "    # The following is to lower the score for groupings which have many small groups and decrease the score for groupings which have too many groups.\n",
    "    lower = sum(1/np.array([len(group) for group in groups])) # The smaller groups, the larger the number becomes\n",
    "    return np.median(medians) * (1/lower) # * np.median([len(group) for group in groups])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T08:53:57.800279Z",
     "start_time": "2023-06-21T08:53:57.800279Z"
    }
   },
   "outputs": [],
   "source": [
    "rsquares = np.linspace(0.5, 1, 11)[:-1]\n",
    "rsquare_groups = []\n",
    "lengths_rsquare_groups = []\n",
    "\n",
    "for i, rsquare in enumerate(rsquares):\n",
    "    groups = []\n",
    "    columns_tqdm = tqdm(scores_df.columns, desc=f\"r2={rsquare}, number: {i+1}/{len(rsquares)}\", total = len(scores_df.columns))\n",
    "    for stock_c in columns_tqdm:\n",
    "        flattened_groups = flatten_table(groups)\n",
    "        if stock_c in flattened_groups:\n",
    "            continue\n",
    "        group = [stock_c]\n",
    "        for stock_r in scores_df.index:\n",
    "            if stock_r in flattened_groups:\n",
    "                continue\n",
    "            if scores_df.loc[stock_r, stock_c] > rsquare:\n",
    "                group.append(stock_r)\n",
    "        if len(group) > 1:\n",
    "            groups.append(group)\n",
    "    groups = sorted(groups, key=lambda lst: -len(lst))\n",
    "    rsquare_groups.append(groups)\n",
    "    lengths_rsquare_groups.append([len(g) for g in groups])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T08:53:57.801322Z",
     "start_time": "2023-06-21T08:53:57.801322Z"
    }
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(lengths_rsquare_groups, index=rsquares).transpose()\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T08:53:57.803797Z",
     "start_time": "2023-06-21T08:53:57.803797Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.lineplot(data = results);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T08:53:57.804815Z",
     "start_time": "2023-06-21T08:53:57.804815Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = px.line(results)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T08:53:57.806889Z",
     "start_time": "2023-06-21T08:53:57.806889Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# groups = all_groups_created[results['score'].idxmax()]\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "for group in groups:\n",
    "    sns.lineplot(data=price_monthly_resampling[group].mean(axis=\"columns\"), legend=False, palette=['black']*len(group), dashes=False, alpha=0.5, linewidth=3)\n",
    "plt.title(f\"Average of each group\")\n",
    "plt.ylim(-4,8)\n",
    "plt.show()\n",
    "\n",
    "for group in groups:\n",
    "    plt.figure(figsize=(15,8))\n",
    "    sns.lineplot(data=price_monthly_resampling[group], legend=False, palette=['b']*len(group), dashes=False, alpha=0.05)\n",
    "    plt.title(f\"Showing {len(group)} stocks\")\n",
    "    plt.ylim(-4,8)\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare with stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
