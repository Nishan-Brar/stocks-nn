{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T12:27:38.355211Z",
     "start_time": "2023-01-05T12:27:38.341552Z"
    }
   },
   "outputs": [],
   "source": [
    "# ! pip uninstall -y tensorflow\n",
    "# ! pip install tensorflow==2.10.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T12:27:47.124593Z",
     "start_time": "2023-01-05T12:27:38.357356Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\brarn\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\brarn\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.11.0 and strictly below 2.14.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.10.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "from outer_function_daily import outer_function\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "import csv\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Activation, Normalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow_addons.metrics import RSquare\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T12:27:47.153857Z",
     "start_time": "2023-01-05T12:27:47.124593Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if it detects GPU\n",
    "tf.config.list_physical_devices('GPU') # need to use `! pip install tensorflow==2.10.*` to use gpu on windows 11 natively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stock price data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T12:27:52.288577Z",
     "start_time": "2023-01-05T12:27:47.211965Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>AA</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABNB</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ACGL</th>\n",
       "      <th>ACHC</th>\n",
       "      <th>...</th>\n",
       "      <th>YUM</th>\n",
       "      <th>Z</th>\n",
       "      <th>ZBH</th>\n",
       "      <th>ZBRA</th>\n",
       "      <th>ZG</th>\n",
       "      <th>ZI</th>\n",
       "      <th>ZION</th>\n",
       "      <th>ZM</th>\n",
       "      <th>ZS</th>\n",
       "      <th>ZTS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1980-01-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.217068</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-01-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.187954</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-01-04</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.187954</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-01-07</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.246180</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-01-08</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.289852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-04</th>\n",
       "      <td>128.880005</td>\n",
       "      <td>26.809999</td>\n",
       "      <td>13.35</td>\n",
       "      <td>55.630001</td>\n",
       "      <td>189.429993</td>\n",
       "      <td>144.149994</td>\n",
       "      <td>133.699997</td>\n",
       "      <td>105.190002</td>\n",
       "      <td>81.989998</td>\n",
       "      <td>74.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>125.650002</td>\n",
       "      <td>44.090000</td>\n",
       "      <td>116.889999</td>\n",
       "      <td>239.369995</td>\n",
       "      <td>42.330002</td>\n",
       "      <td>14.71</td>\n",
       "      <td>38.680000</td>\n",
       "      <td>68.160004</td>\n",
       "      <td>198.259995</td>\n",
       "      <td>182.119995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-05</th>\n",
       "      <td>127.879997</td>\n",
       "      <td>25.240000</td>\n",
       "      <td>13.13</td>\n",
       "      <td>53.160000</td>\n",
       "      <td>193.419998</td>\n",
       "      <td>144.570007</td>\n",
       "      <td>133.710007</td>\n",
       "      <td>104.349998</td>\n",
       "      <td>81.849998</td>\n",
       "      <td>74.209999</td>\n",
       "      <td>...</td>\n",
       "      <td>124.379997</td>\n",
       "      <td>44.290001</td>\n",
       "      <td>115.820000</td>\n",
       "      <td>234.360001</td>\n",
       "      <td>42.520000</td>\n",
       "      <td>14.48</td>\n",
       "      <td>37.389999</td>\n",
       "      <td>68.720001</td>\n",
       "      <td>198.910004</td>\n",
       "      <td>179.649994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-06</th>\n",
       "      <td>128.910004</td>\n",
       "      <td>25.120001</td>\n",
       "      <td>13.48</td>\n",
       "      <td>55.160000</td>\n",
       "      <td>192.320007</td>\n",
       "      <td>146.380005</td>\n",
       "      <td>135.309998</td>\n",
       "      <td>104.940002</td>\n",
       "      <td>79.970001</td>\n",
       "      <td>71.150002</td>\n",
       "      <td>...</td>\n",
       "      <td>124.809998</td>\n",
       "      <td>45.090000</td>\n",
       "      <td>116.129997</td>\n",
       "      <td>234.130005</td>\n",
       "      <td>43.490002</td>\n",
       "      <td>15.50</td>\n",
       "      <td>37.150002</td>\n",
       "      <td>70.940002</td>\n",
       "      <td>197.910004</td>\n",
       "      <td>182.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-07</th>\n",
       "      <td>128.679993</td>\n",
       "      <td>24.940001</td>\n",
       "      <td>13.91</td>\n",
       "      <td>56.250000</td>\n",
       "      <td>194.270004</td>\n",
       "      <td>147.970001</td>\n",
       "      <td>139.839996</td>\n",
       "      <td>104.050003</td>\n",
       "      <td>78.339996</td>\n",
       "      <td>71.980003</td>\n",
       "      <td>...</td>\n",
       "      <td>124.269997</td>\n",
       "      <td>46.730000</td>\n",
       "      <td>117.290001</td>\n",
       "      <td>233.229996</td>\n",
       "      <td>45.009998</td>\n",
       "      <td>15.24</td>\n",
       "      <td>38.380001</td>\n",
       "      <td>71.930000</td>\n",
       "      <td>200.050003</td>\n",
       "      <td>181.830002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-08</th>\n",
       "      <td>127.199997</td>\n",
       "      <td>25.020000</td>\n",
       "      <td>13.76</td>\n",
       "      <td>56.270000</td>\n",
       "      <td>195.710007</td>\n",
       "      <td>149.279999</td>\n",
       "      <td>140.679993</td>\n",
       "      <td>104.510002</td>\n",
       "      <td>79.300003</td>\n",
       "      <td>73.260002</td>\n",
       "      <td>...</td>\n",
       "      <td>124.339996</td>\n",
       "      <td>46.410000</td>\n",
       "      <td>117.300003</td>\n",
       "      <td>236.130005</td>\n",
       "      <td>44.660000</td>\n",
       "      <td>15.64</td>\n",
       "      <td>38.930000</td>\n",
       "      <td>73.059998</td>\n",
       "      <td>198.800003</td>\n",
       "      <td>184.600006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11079 rows × 985 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     A         AA    AAL        AAP        AAPL        ABBV  \\\n",
       "Date                                                                          \n",
       "1980-01-02         NaN   3.217068    NaN        NaN         NaN         NaN   \n",
       "1980-01-03         NaN   3.187954    NaN        NaN         NaN         NaN   \n",
       "1980-01-04         NaN   3.187954    NaN        NaN         NaN         NaN   \n",
       "1980-01-07         NaN   3.246180    NaN        NaN         NaN         NaN   \n",
       "1980-01-08         NaN   3.289852    NaN        NaN         NaN         NaN   \n",
       "...                ...        ...    ...        ...         ...         ...   \n",
       "2023-12-04  128.880005  26.809999  13.35  55.630001  189.429993  144.149994   \n",
       "2023-12-05  127.879997  25.240000  13.13  53.160000  193.419998  144.570007   \n",
       "2023-12-06  128.910004  25.120001  13.48  55.160000  192.320007  146.380005   \n",
       "2023-12-07  128.679993  24.940001  13.91  56.250000  194.270004  147.970001   \n",
       "2023-12-08  127.199997  25.020000  13.76  56.270000  195.710007  149.279999   \n",
       "\n",
       "                  ABNB         ABT       ACGL       ACHC  ...         YUM  \\\n",
       "Date                                                      ...               \n",
       "1980-01-02         NaN         NaN        NaN        NaN  ...         NaN   \n",
       "1980-01-03         NaN         NaN        NaN        NaN  ...         NaN   \n",
       "1980-01-04         NaN         NaN        NaN        NaN  ...         NaN   \n",
       "1980-01-07         NaN         NaN        NaN        NaN  ...         NaN   \n",
       "1980-01-08         NaN         NaN        NaN        NaN  ...         NaN   \n",
       "...                ...         ...        ...        ...  ...         ...   \n",
       "2023-12-04  133.699997  105.190002  81.989998  74.750000  ...  125.650002   \n",
       "2023-12-05  133.710007  104.349998  81.849998  74.209999  ...  124.379997   \n",
       "2023-12-06  135.309998  104.940002  79.970001  71.150002  ...  124.809998   \n",
       "2023-12-07  139.839996  104.050003  78.339996  71.980003  ...  124.269997   \n",
       "2023-12-08  140.679993  104.510002  79.300003  73.260002  ...  124.339996   \n",
       "\n",
       "                    Z         ZBH        ZBRA         ZG     ZI       ZION  \\\n",
       "Date                                                                         \n",
       "1980-01-02        NaN         NaN         NaN        NaN    NaN        NaN   \n",
       "1980-01-03        NaN         NaN         NaN        NaN    NaN        NaN   \n",
       "1980-01-04        NaN         NaN         NaN        NaN    NaN        NaN   \n",
       "1980-01-07        NaN         NaN         NaN        NaN    NaN        NaN   \n",
       "1980-01-08        NaN         NaN         NaN        NaN    NaN        NaN   \n",
       "...               ...         ...         ...        ...    ...        ...   \n",
       "2023-12-04  44.090000  116.889999  239.369995  42.330002  14.71  38.680000   \n",
       "2023-12-05  44.290001  115.820000  234.360001  42.520000  14.48  37.389999   \n",
       "2023-12-06  45.090000  116.129997  234.130005  43.490002  15.50  37.150002   \n",
       "2023-12-07  46.730000  117.290001  233.229996  45.009998  15.24  38.380001   \n",
       "2023-12-08  46.410000  117.300003  236.130005  44.660000  15.64  38.930000   \n",
       "\n",
       "                   ZM          ZS         ZTS  \n",
       "Date                                           \n",
       "1980-01-02        NaN         NaN         NaN  \n",
       "1980-01-03        NaN         NaN         NaN  \n",
       "1980-01-04        NaN         NaN         NaN  \n",
       "1980-01-07        NaN         NaN         NaN  \n",
       "1980-01-08        NaN         NaN         NaN  \n",
       "...               ...         ...         ...  \n",
       "2023-12-04  68.160004  198.259995  182.119995  \n",
       "2023-12-05  68.720001  198.910004  179.649994  \n",
       "2023-12-06  70.940002  197.910004  182.000000  \n",
       "2023-12-07  71.930000  200.050003  181.830002  \n",
       "2023-12-08  73.059998  198.800003  184.600006  \n",
       "\n",
       "[11079 rows x 985 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data\n",
    "stocks_df = pd.read_csv(\"data/price.csv\")\n",
    "\n",
    "# Set date-time index\n",
    "stocks_df['Date'] = pd.to_datetime(stocks_df[\"Date\"], format='%Y-%m-%d')\n",
    "stocks_df = stocks_df.set_index(stocks_df['Date'])\n",
    "stocks_df = stocks_df.drop(columns = [\"Date\"])\n",
    "\n",
    "# Drop all columns which only contain nan values\n",
    "boolean = []\n",
    "for stock in stocks_df.columns:\n",
    "    boolean.append(not stocks_df[stock].isnull().all())\n",
    "stocks_df = stocks_df.iloc[:, boolean]\n",
    "\n",
    "stocks_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical variable data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DBX</th>\n",
       "      <th>CDW</th>\n",
       "      <th>TRV</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AGNC</th>\n",
       "      <th>AAL</th>\n",
       "      <th>SBAC</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>VOYA</th>\n",
       "      <th>PNR</th>\n",
       "      <th>...</th>\n",
       "      <th>SJM</th>\n",
       "      <th>EQH</th>\n",
       "      <th>TRGP</th>\n",
       "      <th>EQIX</th>\n",
       "      <th>CG</th>\n",
       "      <th>NTRA</th>\n",
       "      <th>ATR</th>\n",
       "      <th>ATVI</th>\n",
       "      <th>XYL</th>\n",
       "      <th>DTE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sectors</th>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Financials</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Financials</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Financials</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>...</td>\n",
       "      <td>Consumer Staples</td>\n",
       "      <td>Financials</td>\n",
       "      <td>Energy</td>\n",
       "      <td>Real Estate</td>\n",
       "      <td>Financials</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Materials</td>\n",
       "      <td>Communication Services</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Utilities</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 985 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            DBX                     CDW         TRV  \\\n",
       "sectors  Information Technology  Information Technology  Financials   \n",
       "\n",
       "                           AAPL        AGNC          AAL         SBAC  \\\n",
       "sectors  Information Technology  Financials  Industrials  Real Estate   \n",
       "\n",
       "                           SNOW        VOYA          PNR  ...  \\\n",
       "sectors  Information Technology  Financials  Industrials  ...   \n",
       "\n",
       "                      SJM         EQH    TRGP         EQIX          CG  \\\n",
       "sectors  Consumer Staples  Financials  Energy  Real Estate  Financials   \n",
       "\n",
       "                NTRA        ATR                    ATVI          XYL  \\\n",
       "sectors  Health Care  Materials  Communication Services  Industrials   \n",
       "\n",
       "               DTE  \n",
       "sectors  Utilities  \n",
       "\n",
       "[1 rows x 985 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data\n",
    "cat_variables = pd.read_csv(\"data/categorical.csv\")\n",
    "cat_variables = cat_variables.set_index(\"Unnamed: 0\")\n",
    "cat_variables = cat_variables.rename_axis(None, axis = 0)\n",
    "cat_variables = cat_variables.dropna(axis=\"columns\")\n",
    "\n",
    "# Drop stocks such that the remaining stocks are those in both cat_variables and stocks_df\n",
    "intersection = list(set(stocks_df.columns) & set(cat_variables.columns))\n",
    "cat_variables = cat_variables[intersection]\n",
    "stocks_df = stocks_df[intersection]\n",
    "\n",
    "cat_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T12:27:54.897130Z",
     "start_time": "2023-01-05T12:27:54.883312Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Communication Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Consumer Discretionary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Consumer Staples</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Energy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Financials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Health Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Industrials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Information Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Information technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Materials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Real Estate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Utilities</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   sectors\n",
       "0   Communication Services\n",
       "1   Consumer Discretionary\n",
       "2         Consumer Staples\n",
       "3                   Energy\n",
       "4               Financials\n",
       "5              Health Care\n",
       "6              Industrials\n",
       "7   Information Technology\n",
       "8   Information technology\n",
       "9                Materials\n",
       "10             Real Estate\n",
       "11               Utilities"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get unique categories for each categorical variable\n",
    "cats_df = pd.DataFrame()\n",
    "for cat in cat_variables.index:\n",
    "    uniques = list(cat_variables.loc[cat, :].unique())\n",
    "    categories = np.sort(uniques)\n",
    "    cats_df[cat] = categories\n",
    "\n",
    "cats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical features data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T12:27:55.040653Z",
     "start_time": "2023-01-05T12:27:54.970478Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['BCI', 'CCI', 'CLI', '3 month interbank rate', 'Broad money',\n",
      "       'Construction', 'Consumer prices', 'Manufacturing hourly earnings',\n",
      "       'Industrial production', 'Long-term interest rate',\n",
      "       'Manufacturing confidence indicator', 'Narrow money',\n",
      "       'Overnight interbank rate', 'Car registrations',\n",
      "       'Manufacturing producer prices', 'Retail trade volume',\n",
      "       'Total employment', 'Total manufacturing'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BCI</th>\n",
       "      <th>CCI</th>\n",
       "      <th>CLI</th>\n",
       "      <th>3m%</th>\n",
       "      <th>Broad$</th>\n",
       "      <th>Construction</th>\n",
       "      <th>Consumer_prices</th>\n",
       "      <th>Manu$</th>\n",
       "      <th>Indu_production</th>\n",
       "      <th>Long%</th>\n",
       "      <th>MCI</th>\n",
       "      <th>Narrow$</th>\n",
       "      <th>Overnight%</th>\n",
       "      <th>Cars</th>\n",
       "      <th>producer$</th>\n",
       "      <th>Retail_volume</th>\n",
       "      <th>Total_employment</th>\n",
       "      <th>Total_manu</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1990-01-01</th>\n",
       "      <td>98.82303</td>\n",
       "      <td>100.6509</td>\n",
       "      <td>99.79321</td>\n",
       "      <td>8.16</td>\n",
       "      <td>26.291189</td>\n",
       "      <td>40.385124</td>\n",
       "      <td>53.751419</td>\n",
       "      <td>52.855468</td>\n",
       "      <td>61.105826</td>\n",
       "      <td>8.21</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>26.324891</td>\n",
       "      <td>8.23</td>\n",
       "      <td>138.407385</td>\n",
       "      <td>60.738345</td>\n",
       "      <td>67.509220</td>\n",
       "      <td>119081.0</td>\n",
       "      <td>61.244983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-02</th>\n",
       "      <td>98.82303</td>\n",
       "      <td>100.6509</td>\n",
       "      <td>99.79321</td>\n",
       "      <td>8.16</td>\n",
       "      <td>26.291189</td>\n",
       "      <td>40.385124</td>\n",
       "      <td>53.751419</td>\n",
       "      <td>52.855468</td>\n",
       "      <td>61.105826</td>\n",
       "      <td>8.21</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>26.324891</td>\n",
       "      <td>8.23</td>\n",
       "      <td>138.407385</td>\n",
       "      <td>60.738345</td>\n",
       "      <td>67.509220</td>\n",
       "      <td>119081.0</td>\n",
       "      <td>61.244983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-03</th>\n",
       "      <td>98.82303</td>\n",
       "      <td>100.6509</td>\n",
       "      <td>99.79321</td>\n",
       "      <td>8.16</td>\n",
       "      <td>26.291189</td>\n",
       "      <td>40.385124</td>\n",
       "      <td>53.751419</td>\n",
       "      <td>52.855468</td>\n",
       "      <td>61.105826</td>\n",
       "      <td>8.21</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>26.324891</td>\n",
       "      <td>8.23</td>\n",
       "      <td>138.407385</td>\n",
       "      <td>60.738345</td>\n",
       "      <td>67.509220</td>\n",
       "      <td>119081.0</td>\n",
       "      <td>61.244983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-04</th>\n",
       "      <td>98.82303</td>\n",
       "      <td>100.6509</td>\n",
       "      <td>99.79321</td>\n",
       "      <td>8.16</td>\n",
       "      <td>26.291189</td>\n",
       "      <td>40.385124</td>\n",
       "      <td>53.751419</td>\n",
       "      <td>52.855468</td>\n",
       "      <td>61.105826</td>\n",
       "      <td>8.21</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>26.324891</td>\n",
       "      <td>8.23</td>\n",
       "      <td>138.407385</td>\n",
       "      <td>60.738345</td>\n",
       "      <td>67.509220</td>\n",
       "      <td>119081.0</td>\n",
       "      <td>61.244983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-05</th>\n",
       "      <td>98.82303</td>\n",
       "      <td>100.6509</td>\n",
       "      <td>99.79321</td>\n",
       "      <td>8.16</td>\n",
       "      <td>26.291189</td>\n",
       "      <td>40.385124</td>\n",
       "      <td>53.751419</td>\n",
       "      <td>52.855468</td>\n",
       "      <td>61.105826</td>\n",
       "      <td>8.21</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>26.324891</td>\n",
       "      <td>8.23</td>\n",
       "      <td>138.407385</td>\n",
       "      <td>60.738345</td>\n",
       "      <td>67.509220</td>\n",
       "      <td>119081.0</td>\n",
       "      <td>61.244983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-23</th>\n",
       "      <td>98.91054</td>\n",
       "      <td>97.0624</td>\n",
       "      <td>98.88888</td>\n",
       "      <td>4.51</td>\n",
       "      <td>177.318578</td>\n",
       "      <td>164.796803</td>\n",
       "      <td>125.221820</td>\n",
       "      <td>128.973371</td>\n",
       "      <td>100.598801</td>\n",
       "      <td>3.62</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>655.997485</td>\n",
       "      <td>4.10</td>\n",
       "      <td>37.603772</td>\n",
       "      <td>131.749933</td>\n",
       "      <td>118.300105</td>\n",
       "      <td>159244.0</td>\n",
       "      <td>97.682796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-24</th>\n",
       "      <td>98.91054</td>\n",
       "      <td>97.0624</td>\n",
       "      <td>98.88888</td>\n",
       "      <td>4.51</td>\n",
       "      <td>177.318578</td>\n",
       "      <td>164.796803</td>\n",
       "      <td>125.221820</td>\n",
       "      <td>128.973371</td>\n",
       "      <td>100.598801</td>\n",
       "      <td>3.62</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>655.997485</td>\n",
       "      <td>4.10</td>\n",
       "      <td>37.603772</td>\n",
       "      <td>131.749933</td>\n",
       "      <td>118.300105</td>\n",
       "      <td>159244.0</td>\n",
       "      <td>97.682796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-25</th>\n",
       "      <td>98.91054</td>\n",
       "      <td>97.0624</td>\n",
       "      <td>98.88888</td>\n",
       "      <td>4.51</td>\n",
       "      <td>177.318578</td>\n",
       "      <td>164.796803</td>\n",
       "      <td>125.221820</td>\n",
       "      <td>128.973371</td>\n",
       "      <td>100.598801</td>\n",
       "      <td>3.62</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>655.997485</td>\n",
       "      <td>4.10</td>\n",
       "      <td>37.603772</td>\n",
       "      <td>131.749933</td>\n",
       "      <td>118.300105</td>\n",
       "      <td>159244.0</td>\n",
       "      <td>97.682796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-26</th>\n",
       "      <td>98.91054</td>\n",
       "      <td>97.0624</td>\n",
       "      <td>98.88888</td>\n",
       "      <td>4.51</td>\n",
       "      <td>177.318578</td>\n",
       "      <td>164.796803</td>\n",
       "      <td>125.221820</td>\n",
       "      <td>128.973371</td>\n",
       "      <td>100.598801</td>\n",
       "      <td>3.62</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>655.997485</td>\n",
       "      <td>4.10</td>\n",
       "      <td>37.603772</td>\n",
       "      <td>131.749933</td>\n",
       "      <td>118.300105</td>\n",
       "      <td>159244.0</td>\n",
       "      <td>97.682796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-27</th>\n",
       "      <td>98.91054</td>\n",
       "      <td>97.0624</td>\n",
       "      <td>98.88888</td>\n",
       "      <td>4.51</td>\n",
       "      <td>177.318578</td>\n",
       "      <td>164.796803</td>\n",
       "      <td>125.221820</td>\n",
       "      <td>128.973371</td>\n",
       "      <td>100.598801</td>\n",
       "      <td>3.62</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>655.997485</td>\n",
       "      <td>4.10</td>\n",
       "      <td>37.603772</td>\n",
       "      <td>131.749933</td>\n",
       "      <td>118.300105</td>\n",
       "      <td>159244.0</td>\n",
       "      <td>97.682796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12049 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 BCI       CCI       CLI   3m%      Broad$  Construction  \\\n",
       "Date                                                                       \n",
       "1990-01-01  98.82303  100.6509  99.79321  8.16   26.291189     40.385124   \n",
       "1990-01-02  98.82303  100.6509  99.79321  8.16   26.291189     40.385124   \n",
       "1990-01-03  98.82303  100.6509  99.79321  8.16   26.291189     40.385124   \n",
       "1990-01-04  98.82303  100.6509  99.79321  8.16   26.291189     40.385124   \n",
       "1990-01-05  98.82303  100.6509  99.79321  8.16   26.291189     40.385124   \n",
       "...              ...       ...       ...   ...         ...           ...   \n",
       "2022-12-23  98.91054   97.0624  98.88888  4.51  177.318578    164.796803   \n",
       "2022-12-24  98.91054   97.0624  98.88888  4.51  177.318578    164.796803   \n",
       "2022-12-25  98.91054   97.0624  98.88888  4.51  177.318578    164.796803   \n",
       "2022-12-26  98.91054   97.0624  98.88888  4.51  177.318578    164.796803   \n",
       "2022-12-27  98.91054   97.0624  98.88888  4.51  177.318578    164.796803   \n",
       "\n",
       "            Consumer_prices       Manu$  Indu_production  Long%  MCI  \\\n",
       "Date                                                                   \n",
       "1990-01-01        53.751419   52.855468        61.105826   8.21 -5.6   \n",
       "1990-01-02        53.751419   52.855468        61.105826   8.21 -5.6   \n",
       "1990-01-03        53.751419   52.855468        61.105826   8.21 -5.6   \n",
       "1990-01-04        53.751419   52.855468        61.105826   8.21 -5.6   \n",
       "1990-01-05        53.751419   52.855468        61.105826   8.21 -5.6   \n",
       "...                     ...         ...              ...    ...  ...   \n",
       "2022-12-23       125.221820  128.973371       100.598801   3.62 -3.2   \n",
       "2022-12-24       125.221820  128.973371       100.598801   3.62 -3.2   \n",
       "2022-12-25       125.221820  128.973371       100.598801   3.62 -3.2   \n",
       "2022-12-26       125.221820  128.973371       100.598801   3.62 -3.2   \n",
       "2022-12-27       125.221820  128.973371       100.598801   3.62 -3.2   \n",
       "\n",
       "               Narrow$  Overnight%        Cars   producer$  Retail_volume  \\\n",
       "Date                                                                        \n",
       "1990-01-01   26.324891        8.23  138.407385   60.738345      67.509220   \n",
       "1990-01-02   26.324891        8.23  138.407385   60.738345      67.509220   \n",
       "1990-01-03   26.324891        8.23  138.407385   60.738345      67.509220   \n",
       "1990-01-04   26.324891        8.23  138.407385   60.738345      67.509220   \n",
       "1990-01-05   26.324891        8.23  138.407385   60.738345      67.509220   \n",
       "...                ...         ...         ...         ...            ...   \n",
       "2022-12-23  655.997485        4.10   37.603772  131.749933     118.300105   \n",
       "2022-12-24  655.997485        4.10   37.603772  131.749933     118.300105   \n",
       "2022-12-25  655.997485        4.10   37.603772  131.749933     118.300105   \n",
       "2022-12-26  655.997485        4.10   37.603772  131.749933     118.300105   \n",
       "2022-12-27  655.997485        4.10   37.603772  131.749933     118.300105   \n",
       "\n",
       "            Total_employment  Total_manu  \n",
       "Date                                      \n",
       "1990-01-01          119081.0   61.244983  \n",
       "1990-01-02          119081.0   61.244983  \n",
       "1990-01-03          119081.0   61.244983  \n",
       "1990-01-04          119081.0   61.244983  \n",
       "1990-01-05          119081.0   61.244983  \n",
       "...                      ...         ...  \n",
       "2022-12-23          159244.0   97.682796  \n",
       "2022-12-24          159244.0   97.682796  \n",
       "2022-12-25          159244.0   97.682796  \n",
       "2022-12-26          159244.0   97.682796  \n",
       "2022-12-27          159244.0   97.682796  \n",
       "\n",
       "[12049 rows x 18 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data\n",
    "features_daily = pd.read_csv(\"data/features.csv\")\n",
    "features_daily['Date'] = pd.to_datetime(features_daily[\"Date\"], format='%Y-%m-%d')\n",
    "features_daily = features_daily.set_index(\"Date\")\n",
    "features_daily = features_daily.dropna()\n",
    "\n",
    "# Make names smaller to use in file names\n",
    "print(features_daily.columns)\n",
    "features_daily.columns = ['BCI', 'CCI', 'CLI', '3m%', 'Broad$', 'Construction', 'Consumer_prices', 'Manu$',\n",
    "       'Indu_production', 'Long%', 'MCI', 'Narrow$', 'Overnight%', 'Cars', 'producer$', 'Retail_volume',\n",
    "       'Total_employment', 'Total_manu']\n",
    "\n",
    "features_daily"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training neural network on created data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to a numpy array for speedy opterations later on\n",
    "stocks_np = stocks_df.to_numpy()\n",
    "\n",
    "# Convert to a numpy array for speedy opterations later on\n",
    "cat_variables_np = cat_variables.to_numpy()\n",
    "\n",
    "# Convert to a numpy array for speedy opterations later on\n",
    "features_daily_np = features_daily.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T12:27:55.160287Z",
     "start_time": "2023-01-05T12:27:55.130566Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>lines</th>\n",
       "      <th>years</th>\n",
       "      <th>layers</th>\n",
       "      <th>neurons per layer</th>\n",
       "      <th>total neurons</th>\n",
       "      <th>batch size</th>\n",
       "      <th>technique</th>\n",
       "      <th>model name</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[sectors Consumer_prices Retail_volume Total_e...</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>256</td>\n",
       "      <td>1280</td>\n",
       "      <td>512</td>\n",
       "      <td>base</td>\n",
       "      <td>1</td>\n",
       "      <td>19.053837</td>\n",
       "      <td>0.858044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>2048</td>\n",
       "      <td>base</td>\n",
       "      <td>2</td>\n",
       "      <td>16.163198</td>\n",
       "      <td>0.923965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[sectors Cars Manu$ Narrow$]</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>96</td>\n",
       "      <td>2048</td>\n",
       "      <td>base</td>\n",
       "      <td>3</td>\n",
       "      <td>15.450450</td>\n",
       "      <td>0.923774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>2048</td>\n",
       "      <td>base</td>\n",
       "      <td>4</td>\n",
       "      <td>16.451576</td>\n",
       "      <td>0.919357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[sectors Cars Indu_production Manu$ Narrow$]</td>\n",
       "      <td>44</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>96</td>\n",
       "      <td>2048</td>\n",
       "      <td>base</td>\n",
       "      <td>5</td>\n",
       "      <td>15.620434</td>\n",
       "      <td>0.924702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[sectors Cars Indu_production Manu$ Narrow$]</td>\n",
       "      <td>44</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>96</td>\n",
       "      <td>2048</td>\n",
       "      <td>dropout layers</td>\n",
       "      <td>6</td>\n",
       "      <td>38.215565</td>\n",
       "      <td>0.711032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[]</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>1024</td>\n",
       "      <td>dropout layers</td>\n",
       "      <td>7</td>\n",
       "      <td>20.774151</td>\n",
       "      <td>0.877448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[sectors Cars Indu_production Manu$]</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>192</td>\n",
       "      <td>512</td>\n",
       "      <td>batch normalization</td>\n",
       "      <td>8</td>\n",
       "      <td>16.853075</td>\n",
       "      <td>0.920610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[BCI Broad$ CCI CLI Construction]</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>512</td>\n",
       "      <td>1024</td>\n",
       "      <td>dropout &amp; batch</td>\n",
       "      <td>9</td>\n",
       "      <td>25.313232</td>\n",
       "      <td>0.818963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[sectors Consumer_prices Retail_volume Total_e...</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>256</td>\n",
       "      <td>1280</td>\n",
       "      <td>512</td>\n",
       "      <td>dropout layers</td>\n",
       "      <td>10</td>\n",
       "      <td>62.555294</td>\n",
       "      <td>-0.132937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[]</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>2048</td>\n",
       "      <td>batch normalization</td>\n",
       "      <td>11</td>\n",
       "      <td>16.138048</td>\n",
       "      <td>0.924051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[sectors BCI Broad$ CLI Construction]</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>192</td>\n",
       "      <td>512</td>\n",
       "      <td>dropout layers</td>\n",
       "      <td>12</td>\n",
       "      <td>28.123535</td>\n",
       "      <td>0.815374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[Cars Consumer_prices Indu_production Manu$]</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>256</td>\n",
       "      <td>1536</td>\n",
       "      <td>1024</td>\n",
       "      <td>L1 regularization</td>\n",
       "      <td>13</td>\n",
       "      <td>16.312428</td>\n",
       "      <td>0.918635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[sectors 3m% CCI Narrow$ Overnight% Total_empl...</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>512</td>\n",
       "      <td>2048</td>\n",
       "      <td>L2 regularization</td>\n",
       "      <td>14</td>\n",
       "      <td>16.296637</td>\n",
       "      <td>0.917043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[Long% MCI Retail_volume Total_manu]</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>192</td>\n",
       "      <td>960</td>\n",
       "      <td>256</td>\n",
       "      <td>dropout &amp; batch</td>\n",
       "      <td>15</td>\n",
       "      <td>32.581699</td>\n",
       "      <td>0.707889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[sectors Broad$ CCI Cars producer$]</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>320</td>\n",
       "      <td>2048</td>\n",
       "      <td>batch normalization</td>\n",
       "      <td>16</td>\n",
       "      <td>15.458288</td>\n",
       "      <td>0.916361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             features  lines  years  layers  \\\n",
       "0   [sectors Consumer_prices Retail_volume Total_e...     32      3       5   \n",
       "1                                                  []     36      2       2   \n",
       "2                        [sectors Cars Manu$ Narrow$]     36      3       3   \n",
       "3                                                  []     44      2       2   \n",
       "4        [sectors Cars Indu_production Manu$ Narrow$]     44      3       3   \n",
       "5        [sectors Cars Indu_production Manu$ Narrow$]     44      3       3   \n",
       "6                                                  []     20      2       2   \n",
       "7                [sectors Cars Indu_production Manu$]     24      3       3   \n",
       "8                   [BCI Broad$ CCI CLI Construction]     28      2       4   \n",
       "9   [sectors Consumer_prices Retail_volume Total_e...     32      3       5   \n",
       "10                                                 []     36      2       2   \n",
       "11              [sectors BCI Broad$ CLI Construction]     46      2       3   \n",
       "12       [Cars Consumer_prices Indu_production Manu$]     34      3       6   \n",
       "13  [sectors 3m% CCI Narrow$ Overnight% Total_empl...     50      3       4   \n",
       "14               [Long% MCI Retail_volume Total_manu]     22      2       5   \n",
       "15                [sectors Broad$ CCI Cars producer$]     36      2       2   \n",
       "\n",
       "    neurons per layer  total neurons  batch size            technique  \\\n",
       "0                 256           1280         512                 base   \n",
       "1                  16             32        2048                 base   \n",
       "2                  32             96        2048                 base   \n",
       "3                  16             32        2048                 base   \n",
       "4                  32             96        2048                 base   \n",
       "5                  32             96        2048       dropout layers   \n",
       "6                  32             64        1024       dropout layers   \n",
       "7                  64            192         512  batch normalization   \n",
       "8                 128            512        1024      dropout & batch   \n",
       "9                 256           1280         512       dropout layers   \n",
       "10                 16             32        2048  batch normalization   \n",
       "11                 64            192         512       dropout layers   \n",
       "12                256           1536        1024    L1 regularization   \n",
       "13                128            512        2048    L2 regularization   \n",
       "14                192            960         256      dropout & batch   \n",
       "15                160            320        2048  batch normalization   \n",
       "\n",
       "    model name   val_loss    val_r2  \n",
       "0            1  19.053837  0.858044  \n",
       "1            2  16.163198  0.923965  \n",
       "2            3  15.450450  0.923774  \n",
       "3            4  16.451576  0.919357  \n",
       "4            5  15.620434  0.924702  \n",
       "5            6  38.215565  0.711032  \n",
       "6            7  20.774151  0.877448  \n",
       "7            8  16.853075  0.920610  \n",
       "8            9  25.313232  0.818963  \n",
       "9           10  62.555294 -0.132937  \n",
       "10          11  16.138048  0.924051  \n",
       "11          12  28.123535  0.815374  \n",
       "12          13  16.312428  0.918635  \n",
       "13          14  16.296637  0.917043  \n",
       "14          15  32.581699  0.707889  \n",
       "15          16  15.458288  0.916361  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_folder = \"results\"\n",
    "overview_folder = \"overview\"\n",
    "details_folder = \"details\"\n",
    "\n",
    "# Create/load file to store results of each model\n",
    "try:\n",
    "    os.makedirs(f\"{root_folder}/{overview_folder}\")\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "\n",
    "model_results_path = f\"{root_folder}/{overview_folder}/model results.csv\"\n",
    "try:\n",
    "    results = pd.read_csv(model_results_path)\n",
    "except FileNotFoundError:\n",
    "    # If the file does not exist then we create the file\n",
    "    with open(model_results_path, \"w\") as f:\n",
    "        f.write(\",\".join([\"features\",\"lines\", \"years\", \"layers\", \"neurons per layer\", \"total neurons\", \"batch size\", \"technique\", \"model name\",\"val_loss\", \"val_r2\"]) + \"\\n\")\n",
    "    results = pd.read_csv(model_results_path)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-05T12:27:55.253812Z",
     "start_time": "2023-01-05T12:27:55.240604Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def plot(history, model, x_test, y_train, y_test, features_string, batch_size, i, test_predictions, R2_score):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(13, 5), dpi=300)\n",
    "\n",
    "    # PLot actual vs prediction scatter plot\n",
    "    test_predictions = test_predictions.flatten()\n",
    "    ax[0].scatter(y_test, test_predictions, alpha=0.01)\n",
    "    ax[0].set_xlabel('True Values')\n",
    "    ax[0].set_ylabel('Predictions')\n",
    "\n",
    "    # Plot y=x line\n",
    "    # ax[0].axline((0, 0), slope=1, c='green', linewidth=2)\n",
    "    points = [0, max(max(y_test), max(test_predictions))]\n",
    "    ax[0].plot(points, points, color=\"green\", linewidth = 3)\n",
    "    ax[0].set_title(\"True values against predictions\")\n",
    "    ax[0].set_yscale('log')\n",
    "    ax[0].set_xscale('log')\n",
    "\n",
    "    # Plot training and testing r-squared\n",
    "    ax[1].plot(history.history['loss'], label='loss')\n",
    "    ax[1].plot(history.history['val_loss'], label='val_loss')\n",
    "    ax[1].set_xlabel('Epoch')\n",
    "    ax[1].set_ylabel('Error')\n",
    "    ax[1].set_title('loss')\n",
    "\n",
    "    fig.suptitle(f\"Val R2 = {R2_score}, Val loss={round(history.history['val_loss'][-1],3)}, BS={batch_size}, result index={i}, {features_string}\", fontsize=\"small\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "MAX_EPOCHS = 50\n",
    "PATIENCE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(NUMBER_OF_LINES, NUMBER_OF_YEARS_TO_CONSIDER,layer,neuron,BATCH_SIZE,technique,cats_subset,features_subset, results = results):\n",
    "    # Sort for consistency in file names and such\n",
    "    cats_subset.sort()\n",
    "    features_subset.sort()\n",
    "\n",
    "    # Indexes of features columns in df to be used to find corresponding columns in numpy\n",
    "    def get_feature_index(feature):\n",
    "        return list(features_daily.columns).index(feature)\n",
    "    def get_cat_index(cat):\n",
    "        return list(cat_variables.index).index(cat)\n",
    "\n",
    "    cats_subset_indexes = []\n",
    "    for var in cats_subset:\n",
    "        cats_subset_indexes.append(get_cat_index(var))\n",
    "\n",
    "    features_subset_indexes = []\n",
    "    for var in features_subset:\n",
    "        features_subset_indexes.append(get_feature_index(var))\n",
    "\n",
    "\n",
    "\n",
    "    p = Pool(os.cpu_count())\n",
    "    first_index = NUMBER_OF_YEARS_TO_CONSIDER*365+1 # `+1` needed since slicing is end-exclusive\n",
    "    range_iterations = range(first_index, len(stocks_np) - 365)\n",
    "\n",
    "    iterations = tqdm(range_iterations,\n",
    "                        desc=f\"Working on Dataset: {NUMBER_OF_LINES} lines, {NUMBER_OF_YEARS_TO_CONSIDER} years\",\n",
    "                        disable=False)\n",
    "\n",
    "    result_list = p.map(partial(outer_function,\n",
    "                                stocks_np = stocks_np,\n",
    "                                NUMBER_OF_YEARS_TO_CONSIDER = NUMBER_OF_YEARS_TO_CONSIDER,\n",
    "                                NUMBER_OF_LINES = NUMBER_OF_LINES,\n",
    "                                features_subset_indexes = features_subset_indexes,\n",
    "                                features_np = features_daily_np,\n",
    "                                cats_np = cat_variables_np,\n",
    "                                cats_index = cats_subset_indexes,\n",
    "                                cats_df = cats_df,\n",
    "                                dates = np.array(stocks_df.index),\n",
    "                                stocks = np.array(stocks_df.columns)\n",
    "                                ),\n",
    "                        iterations)\n",
    "\n",
    "    data = np.vstack([result[0] for result in result_list])\n",
    "    data_dates = np.hstack([result[1] for result in result_list])\n",
    "    data_stocks = np.hstack([result[2] for result in result_list])\n",
    "\n",
    "    cats_dict = dict()\n",
    "    for k in cats_subset_indexes:\n",
    "        cats_dict[k] = np.hstack([result_list[i][3][k] for i in range(len(result_list))])\n",
    "\n",
    "    features_dict = dict()\n",
    "    for k in features_subset_indexes:\n",
    "        features_dict[k] = np.vstack([result_list[i][4][k] for i in range(len(result_list))])\n",
    "\n",
    "    # To ensure we don't run into a memory error\n",
    "    del result_list\n",
    "\n",
    "    # Create folders\n",
    "    models_path = f'{root_folder}/{details_folder}/models'\n",
    "    graphs_path = f'{root_folder}/{details_folder}/training & validation details'\n",
    "    try:\n",
    "        os.makedirs(graphs_path)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        os.makedirs(models_path)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "    # Get name of next model\n",
    "    files = os.listdir(models_path)\n",
    "    numbers = sorted([int(file_name[:-3]) for file_name in files])\n",
    "    try:\n",
    "        model_name =  str(numbers[-1] + 1)\n",
    "    except IndexError:\n",
    "        model_name = \"1\"\n",
    "\n",
    "    # Creating neural networks\n",
    "    features_string = f\"{cats_subset + features_subset}\".replace(\"'\",\"\").replace(\",\",\"\")\n",
    "\n",
    "    categorical_dummy_dfs_list = []\n",
    "    for c in cats_subset_indexes:\n",
    "        categorical_dummy_dfs_list.append(pd.get_dummies(cats_dict[c]).iloc[:,:-1])\n",
    "\n",
    "\n",
    "    # The `data` list must go last since the rest of the script expects the dependent variable to be the last column !!\n",
    "    model_data = np.hstack(categorical_dummy_dfs_list + [features_dict[f] for f in features_subset_indexes] + [data])\n",
    "    del cats_dict, categorical_dummy_dfs_list, features_dict, data\n",
    "\n",
    "\n",
    "    # Create data for model\n",
    "    tuples = list(zip(data_dates, data_stocks))\n",
    "    index = pd.MultiIndex.from_tuples(tuples, names=[\"dates\", \"stocks\"])\n",
    "    model_data = pd.DataFrame(model_data, index=index)\n",
    "\n",
    "    # Split the data into 60% train and 40% for the combined test and validation sets (the test data won't be used in this notebook.)\n",
    "    x_train, x_temp, y_train, y_temp = train_test_split(model_data.iloc[:,:-1], model_data.iloc[:,-1], test_size=0.4, random_state=42, shuffle=False)\n",
    "    \n",
    "    # Split the temp data into test and validation sets (50% each of the temp data)\n",
    "    x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.5, random_state=42, shuffle=False)\n",
    "\n",
    "    # # Normalize the data\n",
    "    # normalizer = preprocessing.Normalization(axis=-1)\n",
    "    # normalizer.adapt(x_train)\n",
    "\n",
    "    model = Sequential()\n",
    "    # model.add(normalizer)\n",
    "    if technique == \"dropout & batch\":\n",
    "        for _ in range(layer):\n",
    "            model.add(Dense(neuron))\n",
    "            model.add(BatchNormalization(axis=1))\n",
    "            model.add(Activation(\"relu\"))\n",
    "            model.add(Dropout(0.5))\n",
    "    else:\n",
    "        for _ in range(layer):\n",
    "            model.add(Dense(neuron))\n",
    "            if technique == \"batch regularisation\":\n",
    "                model.add(BatchNormalization(axis=1))\n",
    "\n",
    "            model.add(Activation(\"relu\"))\n",
    "\n",
    "            if technique == \"dropout layers\":\n",
    "                model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(loss='mean_absolute_error',\n",
    "                    optimizer= Adam(learning_rate=0.00001),\n",
    "                    metrics=[RSquare()])\n",
    "\n",
    "    checkpoint_cb = ModelCheckpoint(f\"{models_path}/{model_name}.h5\",\n",
    "                                    monitor='val_loss',\n",
    "                                    save_best_only=True,\n",
    "                                    verbose=0,\n",
    "                                    save_weights_only=False,\n",
    "                                    mode = \"min\")\n",
    "    early_stopping_cb = EarlyStopping(monitor = \"val_loss\",\n",
    "                                        patience = PATIENCE, # No. epochs with no improvement after which training is stopped.\n",
    "                                        restore_best_weights=True,\n",
    "                                        verbose = 0,\n",
    "                                        min_delta = 0.01, \n",
    "                                        mode = \"min\")\n",
    "\n",
    "\n",
    "    # tensorboard_callback = tf.keras.callbacks.TensorBoard(f\"{root_folder}/{details_folder}/{technique}/logs/{data_name}/{model_name}\")\n",
    "\n",
    "    # reducelr_cb = ReduceLROnPlateau(monitor='val_r_square',\n",
    "    #                                 factor=0.5,\n",
    "    #                                 patience=REDUCE_LR_PATIENCE,\n",
    "    #                                 verbose = 0,\n",
    "    #                                 mode = \"max\")\n",
    "\n",
    "    history = model.fit(\n",
    "        x_train, y_train,\n",
    "        validation_data = (x_val, y_val),\n",
    "        verbose=1,\n",
    "        epochs=MAX_EPOCHS,\n",
    "        callbacks=[checkpoint_cb, early_stopping_cb], # , tensorboard_callback , reducelr_cb\n",
    "        batch_size = BATCH_SIZE)\n",
    "\n",
    "    model = tf.keras.models.load_model(f\"{models_path}/{model_name}.h5\")\n",
    "\n",
    "    # Calculate r-squared\n",
    "    test_predictions = model.predict(x_val, batch_size=BATCH_SIZE)\n",
    "    plt.close(\"all\")\n",
    "    index = len(results)\n",
    "    val_loss = min(history.history[\"val_loss\"])\n",
    "    R2_score = r2_score(y_val, test_predictions)\n",
    "    fig = plot(history, model, x_val, y_train, y_val, features_string, BATCH_SIZE, index, test_predictions, R2_score)\n",
    "    \n",
    "    plt.savefig(\n",
    "        f'{graphs_path}/{model_name}.png',\n",
    "        bbox_inches='tight',\n",
    "        dpi = 300\n",
    "    )\n",
    "\n",
    "\n",
    "    # Add result to `results` dataframe and to \"model results.csv\"\n",
    "    total_neurons = layer * neuron\n",
    "    result_row = [features_string, NUMBER_OF_LINES, NUMBER_OF_YEARS_TO_CONSIDER, layer, neuron, total_neurons, BATCH_SIZE, technique, model_name, val_loss, R2_score]\n",
    "    new_row = pd.DataFrame([{\"features\": features_string,\n",
    "                            \"lines\": NUMBER_OF_LINES,\n",
    "                            \"years\": NUMBER_OF_YEARS_TO_CONSIDER,\n",
    "                            \"layers\": layer,\n",
    "                            \"neurons per layer\": neuron,\n",
    "                            \"total neurons\": total_neurons,\n",
    "                            \"batch size\": BATCH_SIZE,\n",
    "                            \"technique\": technique,\n",
    "                            \"model name\": model_name,\n",
    "                            \"val_loss\": val_loss,\n",
    "                            \"val_r2\": R2_score}])\n",
    "    results = pd.concat([results, new_row], ignore_index=True)\n",
    "\n",
    "    with open(f\"{root_folder}/{overview_folder}/model results.csv\", \"a\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(result_row)\n",
    "\n",
    "\n",
    "    p.close()\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NUMBER_OF_LINES</th>\n",
       "      <th>NUMBER_OF_YEARS_TO_CONSIDER</th>\n",
       "      <th>layer</th>\n",
       "      <th>neuron</th>\n",
       "      <th>BATCH_SIZE</th>\n",
       "      <th>technique</th>\n",
       "      <th>cats_subset</th>\n",
       "      <th>features_subset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>512</td>\n",
       "      <td>dropout layers</td>\n",
       "      <td>[sectors]</td>\n",
       "      <td>[BCI, CLI, Broad$, Construction]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>256</td>\n",
       "      <td>1024</td>\n",
       "      <td>L1 regularization</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Consumer_prices, Manu$, Indu_production, Cars]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>2048</td>\n",
       "      <td>L2 regularization</td>\n",
       "      <td>[sectors]</td>\n",
       "      <td>[CCI, 3m%, Narrow$, Overnight%, Total_employment]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>192</td>\n",
       "      <td>256</td>\n",
       "      <td>dropout &amp; batch</td>\n",
       "      <td>[]</td>\n",
       "      <td>[MCI, Long%, Retail_volume, Total_manu]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>2048</td>\n",
       "      <td>batch normalization</td>\n",
       "      <td>[sectors]</td>\n",
       "      <td>[producer$, Cars, CCI, Broad$]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>128</td>\n",
       "      <td>512</td>\n",
       "      <td>base</td>\n",
       "      <td>[]</td>\n",
       "      <td>[BCI, CLI, Manu$, Retail_volume, Total_employm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  NUMBER_OF_LINES NUMBER_OF_YEARS_TO_CONSIDER layer neuron BATCH_SIZE  \\\n",
       "0              46                           2     3     64        512   \n",
       "1              34                           3     6    256       1024   \n",
       "2              50                           3     4    128       2048   \n",
       "3              22                           2     5    192        256   \n",
       "4              36                           2     2    160       2048   \n",
       "5              48                           3     7    128        512   \n",
       "\n",
       "             technique cats_subset  \\\n",
       "0       dropout layers   [sectors]   \n",
       "1    L1 regularization          []   \n",
       "2    L2 regularization   [sectors]   \n",
       "3      dropout & batch          []   \n",
       "4  batch normalization   [sectors]   \n",
       "5                 base          []   \n",
       "\n",
       "                                     features_subset  \n",
       "0                   [BCI, CLI, Broad$, Construction]  \n",
       "1    [Consumer_prices, Manu$, Indu_production, Cars]  \n",
       "2  [CCI, 3m%, Narrow$, Overnight%, Total_employment]  \n",
       "3            [MCI, Long%, Retail_volume, Total_manu]  \n",
       "4                     [producer$, Cars, CCI, Broad$]  \n",
       "5  [BCI, CLI, Manu$, Retail_volume, Total_employm...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dictionary of arguments and their values\n",
    "arguments = {\n",
    "    'NUMBER_OF_LINES': [20, 24, 28, 32, 36, 36, 44, 44, 44, 20, 24, 28, 32, 36, 36, 44, 44, 48, 48, 42, 36, 30, 24, 34, 44, 46, 28, 38, 32, 40, 20],\n",
    "    'NUMBER_OF_YEARS_TO_CONSIDER': [2, 3, 2, 3, 2, 3, 2, 3, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 3, 2, 3, 3, 3, 2, 3, 2, 3, 2, 2, 2],\n",
    "    'layer': [2, 3, 4, 5, 2, 3, 2, 3, 3, 2, 3, 4, 5, 2, 3, 2, 3, 4, 5, 4, 2, 5, 4, 4, 2, 5, 2, 5, 3, 3, 3],\n",
    "    'neuron': [32, 64, 128, 256, 16, 32, 16, 32, 32, 32, 64, 128, 256, 16, 32, 16, 32, 64, 128, 128, 64, 256, 128, 128, 64, 256, 64, 256, 32, 32, 32],\n",
    "    'BATCH_SIZE': [1024, 512, 1024, 512, 2048, 2048, 2048, 2048, 2048, 1024, 512, 1024, 512, 2048, 2048, 2048, 2048, 1024, 512, 2048, 2048, 512, 1024, 512, 1024, 512, 2048, 1024, 1024, 512, 2048],\n",
    "    'technique': ['base', 'base', 'base', 'base', 'base', 'base', 'base', 'base', 'dropout layers', 'dropout layers', 'batch normalization', 'dropout & batch', 'dropout layers', 'batch normalization', 'dropout & batch', 'dropout & batch', 'dropout layers', 'batch normalization', 'dropout & batch', 'base', 'batch normalization', 'dropout & batch', 'base', 'base', 'batch normalization', 'dropout & batch', 'batch normalization', 'dropout & batch', 'dropout layers', 'dropout layers', 'base'],\n",
    "    'cats_subset': [[], ['sectors'], [], ['sectors'], [], ['sectors'], [], ['sectors'], ['sectors'], [], ['sectors'], [], ['sectors'], [], ['sectors'], [], ['sectors'], [], ['sectors'], [], [], [], [], [], [], [], [], [], [], [], []],\n",
    "    'features_subset': [[], ['Cars', 'Indu_production', 'Manu$'], ['BCI', 'Broad$', 'CCI', 'CLI', 'Construction'], ['Consumer_prices', 'Retail_volume', 'Total_employment', 'Total_manu'], [], ['Cars', 'Manu$', 'Narrow$'], [], ['Cars', 'Indu_production', 'Manu$', 'Narrow$'], ['Cars', 'Indu_production', 'Manu$', 'Narrow$'], [], ['Cars', 'Indu_production', 'Manu$'], ['BCI', 'Broad$', 'CCI', 'CLI', 'Construction'], ['Consumer_prices', 'Retail_volume', 'Total_employment', 'Total_manu'], [], ['Cars', 'Manu$', 'Narrow$'], [], ['Cars', 'Indu_production', 'Manu$', 'Narrow$'], ['BCI', 'Broad$', 'CCI', 'CLI', 'Construction', 'Consumer_prices', 'Retail_volume'], ['Cars', 'Indu_production', 'Manu$', 'Narrow$', 'Total_employment', 'Total_manu'], [], [], [], [], [], [], [], [], [], [], [], []]\n",
    "}\n",
    "\n",
    "\n",
    "args_df = pd.DataFrame.from_dict(arguments, orient='index').transpose()\n",
    "args_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(args_df)):\n",
    "    args = args_df.loc[i]\n",
    "    create_model(*args)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-10.m102",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-10:m102"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
